{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocab of chars and mapping to/from ints\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ----> e\n",
      "..e ----> m\n",
      ".em ----> m\n",
      "emm ----> a\n",
      "mma ----> .\n",
      "olivia\n",
      "... ----> o\n",
      "..o ----> l\n",
      ".ol ----> i\n",
      "oli ----> v\n",
      "liv ----> i\n",
      "ivi ----> a\n",
      "via ----> .\n",
      "ava\n",
      "... ----> a\n",
      "..a ----> v\n",
      ".av ----> a\n",
      "ava ----> .\n",
      "isabella\n",
      "... ----> i\n",
      "..i ----> s\n",
      ".is ----> a\n",
      "isa ----> b\n",
      "sab ----> e\n",
      "abe ----> l\n",
      "bel ----> l\n",
      "ell ----> a\n",
      "lla ----> .\n",
      "sophia\n",
      "... ----> s\n",
      "..s ----> o\n",
      ".so ----> p\n",
      "sop ----> h\n",
      "oph ----> i\n",
      "phi ----> a\n",
      "hia ----> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many chars we take to predict the next?\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
    "        context = context[1:] + [ix] # crop and append\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3687,  0.8670])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cat(torch.unbind(emb, 1), 1).shape # this is inefficient vs .view() because it creates a new tensor after concatinating taking up memory\n",
    "#emb.view(32, 6) == torch.cat(torch.unbind(emb, 1), 1) this comparison returns true showing view functions the same as cat and unbind while reducing memory use. view is just more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6,100))\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of emb.shape[0] you can put -1 and pytorch will infer the shape\n",
    "h = torch.tanh(emb.view(emb.shape[0], 6) @ W1 + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9858, -0.9993,  0.9861,  ...,  0.5308, -0.9999,  0.9579],\n",
       "        [ 0.7664, -0.9973, -0.9330,  ...,  0.9999, -0.9986,  0.9998],\n",
       "        [ 0.8577,  0.9886, -0.8883,  ...,  0.6646, -0.9996, -0.8549],\n",
       "        ...,\n",
       "        [-0.9469, -0.9917,  0.6785,  ...,  0.9808, -0.7611,  0.9899],\n",
       "        [ 0.6100,  0.6857, -0.1497,  ...,  0.9634, -0.9990,  0.5112],\n",
       "        [ 0.4269,  0.9952,  0.9121,  ..., -0.9945, -0.9961,  0.9595]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = counts / counts.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.4266)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -prob[torch.arange(32), Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganize everything above-------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27,2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # num params in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.769712448120117\n",
      "13.656402587890625\n",
      "11.298768997192383\n",
      "9.452457427978516\n",
      "7.984262466430664\n",
      "6.891321182250977\n",
      "6.1000142097473145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.452036380767822\n",
      "4.898151874542236\n",
      "4.414664268493652\n",
      "3.985849142074585\n",
      "3.6028308868408203\n",
      "3.262141704559326\n",
      "2.961381196975708\n",
      "2.6982972621917725\n",
      "2.469712972640991\n",
      "2.271660804748535\n",
      "2.101283550262451\n",
      "1.9571771621704102\n",
      "1.8374855518341064\n",
      "1.7380964756011963\n",
      "1.6535117626190186\n",
      "1.579089879989624\n",
      "1.5117664337158203\n",
      "1.449604868888855\n",
      "1.3913120031356812\n",
      "1.3359923362731934\n",
      "1.283052682876587\n",
      "1.2321912050247192\n",
      "1.18338143825531\n",
      "1.1367988586425781\n",
      "1.092664361000061\n",
      "1.0510926246643066\n",
      "1.0120269060134888\n",
      "0.9752706289291382\n",
      "0.9405567049980164\n",
      "0.9076126217842102\n",
      "0.8761922717094421\n",
      "0.8460891246795654\n",
      "0.8171356916427612\n",
      "0.78919917345047\n",
      "0.7621746063232422\n",
      "0.7359814047813416\n",
      "0.7105579972267151\n",
      "0.6858610510826111\n",
      "0.6618654131889343\n",
      "0.638565719127655\n",
      "0.6159819960594177\n",
      "0.5941659808158875\n",
      "0.573210597038269\n",
      "0.5532563328742981\n",
      "0.5344882011413574\n",
      "0.5171167850494385\n",
      "0.5013313293457031\n",
      "0.4872424304485321\n",
      "0.47484028339385986\n",
      "0.4639976918697357\n",
      "0.4545143246650696\n",
      "0.44617074728012085\n",
      "0.4387662708759308\n",
      "0.43213310837745667\n",
      "0.4261387586593628\n",
      "0.4206797480583191\n",
      "0.41567525267601013\n",
      "0.41106143593788147\n",
      "0.4067871868610382\n",
      "0.40281057357788086\n",
      "0.3990972936153412\n",
      "0.39561811089515686\n",
      "0.3923477828502655\n",
      "0.38926535844802856\n",
      "0.38635197281837463\n",
      "0.3835916519165039\n",
      "0.38096991181373596\n",
      "0.37847423553466797\n",
      "0.37609291076660156\n",
      "0.3738163113594055\n",
      "0.37163493037223816\n",
      "0.3695409595966339\n",
      "0.3675268292427063\n",
      "0.3655855357646942\n",
      "0.36371126770973206\n",
      "0.36189839243888855\n",
      "0.3601416051387787\n",
      "0.35843631625175476\n",
      "0.35677802562713623\n",
      "0.3551627993583679\n",
      "0.35358697175979614\n",
      "0.352046936750412\n",
      "0.35053977370262146\n",
      "0.34906241297721863\n",
      "0.34761226177215576\n",
      "0.34618669748306274\n",
      "0.34478363394737244\n",
      "0.3434009253978729\n",
      "0.34203681349754333\n",
      "0.3406899571418762\n",
      "0.3393586277961731\n",
      "0.33804190158843994\n",
      "0.3367388844490051\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    # forward pass\n",
    "    emb = C[X] # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    #counts = logits.exp()                                  | these 3 lines are equivalent to F.cross_entropy(logits, Y)\n",
    "    #prob = counts / counts.sum(1, keepdim=True)            | in F.cross_entropy, pytorch doesn't make all the tensors \n",
    "    #loss = -prob[torch.arange(32), Y].log().mean()         | like in the 3 lines here so it is more efficient as extra memory isnt being taken up\n",
    "    loss = F.cross_entropy(logits, Y) # reasons to do cross_entropy over the 3 lines, forward/backward pass is more efficient, and numerically more well behaved\n",
    "    print(loss.item())\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    # update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
